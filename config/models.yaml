# Model Configuration and Download URLs

llm:
  recommended:
    - name: "Qwen2.5-1.5B-Instruct"
      file: "qwen2.5-1.5b-instruct-q4_k_m.gguf"
      size: "1.0GB"
      url: "https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct-GGUF/resolve/main/qwen2.5-1.5b-instruct-q4_k_m.gguf"
      description: "Best for Indonesian reasoning, 4-bit quantized"
      priority: 1
      
    - name: "Llama-3.2-1B-Instruct"
      file: "llama-3.2-1b-instruct-q4_k_m.gguf"
      size: "0.8GB"
      url: "https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-Q4_K_M.gguf"
      description: "Smaller, faster, good general reasoning"
      priority: 2

    - name: "Gemma-2-2B-Instruct"
      file: "gemma-2-2b-instruct-q4_k_m.gguf"
      size: "1.4GB"
      url: "https://huggingface.co/bartowski/gemma-2-2b-it-GGUF/resolve/main/gemma-2-2b-it-Q4_K_M.gguf"
      description: "Most capable but larger"
      priority: 3

whisper:
  models:
    - name: "whisper-tiny"
      file: "ggml-tiny.bin"
      size: "75MB"
      url: "https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-tiny.bin"
      description: "Fastest, least accurate"
      
    - name: "whisper-base"
      file: "ggml-base.bin"
      size: "142MB"
      url: "https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-base.bin"
      description: "Good balance (RECOMMENDED)"
      
    - name: "whisper-small"
      file: "ggml-small.bin"
      size: "466MB"
      url: "https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-small.bin"
      description: "Better accuracy, slower"

# OCR doesn't need download (uses system Tesseract)
# PaddleOCR will be installed via pip if needed
